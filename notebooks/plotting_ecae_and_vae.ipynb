{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import os\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "import h5py\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.calibration import calibration_curve\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/remote/gpu06/ernst/Master_Thesis/vae_calo_challenge/CaloINN\n"
     ]
    }
   ],
   "source": [
    "cd ../../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/remote/gpu06/ernst/Master_Thesis/vae_calo_challenge/CaloINN/src\n"
     ]
    }
   ],
   "source": [
    "cd src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from model import CINN\n",
    "from trainer import ECAETrainer\n",
    "import data_util\n",
    "from documenter import Documenter\n",
    "from plotter import Plotter\n",
    "from matplotlib import cm\n",
    "from myDataLoader import MyDataLoader\n",
    "from calc_obs import *\n",
    "from model import CINN\n",
    "import plotting\n",
    "import HighLevelFeatures as HLF\n",
    "from XMLHandler import XMLHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import cm\n",
    "# from matplotlib.transforms import Bbox\n",
    "\n",
    "import data_util\n",
    "from calc_obs import *\n",
    "import math\n",
    "import torch\n",
    "\n",
    "from evaluate_plotting_helper import *\n",
    "\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['mathtext.default'] = 'rm'\n",
    "plt.rcParams['text.usetex'] = True\n",
    "\n",
    "labelfont = FontProperties()\n",
    "labelfont.set_family('serif')\n",
    "labelfont.set_name('Times New Roman')\n",
    "labelfont.set_size(20)\n",
    "\n",
    "axislabelfont = FontProperties()\n",
    "axislabelfont.set_family('serif')\n",
    "axislabelfont.set_name('Times New Roman')\n",
    "axislabelfont.set_size(20)\n",
    "\n",
    "tickfont = FontProperties()\n",
    "tickfont.set_family('serif')\n",
    "tickfont.set_name('Times New Roman')\n",
    "tickfont.set_size(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/remote/gpu06/ernst/Master_Thesis/vae_calo_challenge/CaloINN\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def plot_hist(\n",
    "        file_name,\n",
    "        data,\n",
    "        reference,\n",
    "        p_ref='photon',\n",
    "        axis_label=None,\n",
    "        xscale='linear',\n",
    "        yscale='log',\n",
    "        vmin=None,\n",
    "        vmax=None,\n",
    "        n_bins=50,\n",
    "        ymin=None,\n",
    "        ymax=None,\n",
    "        ax=None,\n",
    "        panel_ax=None,\n",
    "        panel_scale=\"linear\",\n",
    "        density=True,\n",
    "        labels=None,\n",
    "        errorbars_true=False,\n",
    "        errorbars_fake=False):\n",
    "\n",
    "    if type(errorbars_fake) == bool:\n",
    "        errorbars_fake = [errorbars_fake]\n",
    "    \n",
    "    if type(data)==list and type(data[0])==np.ndarray:\n",
    "        data_list = data\n",
    "    else:\n",
    "        data_list = [data]\n",
    "        \n",
    "    if len(errorbars_fake) != len(data_list):\n",
    "        assert len(errorbars_fake) == 1, \"Wrong size for the errorbars index\"\n",
    "        \n",
    "        errorbars_fake = [errorbars_fake[0] for _ in range(len(data_list))]\n",
    "    \n",
    "    for i in range(len(data_list)):\n",
    "        data_list[i] = data_list[i][np.isfinite(data_list[i])]\n",
    "    \n",
    "    reference = reference[np.isfinite(reference)]\n",
    "\n",
    "    all_data = data_list + [reference]\n",
    "\n",
    "    # Set the plotting boundaries\n",
    "    if vmin is None:\n",
    "        vmin = np.inf\n",
    "        for elem in all_data:\n",
    "            vmin = np.min([np.min(elem), vmin])\n",
    "    if vmax is None:\n",
    "        vmax = -np.inf\n",
    "        for elem in all_data:\n",
    "            vmax = np.max([np.max(elem), vmax])\n",
    "            \n",
    "    # Get the bins (Modifications needed if logscale is used)\n",
    "    if xscale=='log':\n",
    "        \n",
    "        if vmin==0:\n",
    "            vmin = np.inf     \n",
    "            for elem in all_data:\n",
    "                vmin = np.min([np.min(elem[elem>1e-7]), vmin])\n",
    "                \n",
    "        if isinstance(n_bins, int):\n",
    "            bins = np.logspace(np.log10(vmin), np.log10(vmax), n_bins)\n",
    "        else:\n",
    "            bins = n_bins\n",
    "    else:\n",
    "        if isinstance(n_bins, int):\n",
    "            bins = np.linspace(vmin, vmax, n_bins)\n",
    "        else:\n",
    "            bins = n_bins\n",
    "    \n",
    "    colors = cm.gnuplot2(np.linspace(0.2, 0.8, 3))\n",
    "    if p_ref == 'electron':\n",
    "        color = colors[0]\n",
    "    elif p_ref == 'photon':\n",
    "        color = colors[1]\n",
    "    elif p_ref == 'pion':\n",
    "        color = colors[2]\n",
    "    else:\n",
    "        color = 'blue'\n",
    "        \n",
    "    create_fig = False\n",
    "    if ax is None:\n",
    "        create_fig = True\n",
    "        fig, ax = plt.subplots(1,1,figsize=(6,6))    \n",
    "        \n",
    "        \n",
    "    # Plot the reference data\n",
    "    if not errorbars_true:\n",
    "        ns_1, bins_1, patches_1 = ax.hist(reference, bins=bins, histtype='stepfilled',\n",
    "                alpha=0.5, color=color, density=density, label='GEANT')\n",
    "    else:\n",
    "        dup_last = lambda a: np.append(a, a[-1])\n",
    "\n",
    "        bins_1 = bins\n",
    "        \n",
    "        counts, _ = np.histogram(reference, bins_1, density=False)\n",
    "        ns_1, _ = np.histogram(reference, bins_1, density=True)\n",
    "        \n",
    "        mask = (counts == 0)\n",
    "        counts[mask] = 1\n",
    "        \n",
    "        ref_err = ns_1 / np.sqrt(counts)\n",
    "            \n",
    "        ref_err[mask] = 0\n",
    "        \n",
    "        ax.step(bins_1, dup_last(ns_1), color=\"blue\", alpha=1,\n",
    "                        linewidth=1, where='post', label='GEANT')\n",
    "        \n",
    "        ax.step(bins_1, dup_last(ns_1 - ref_err), color=\"blue\", alpha=0.5,\n",
    "                        linewidth=0.5, where='post')\n",
    "        ax.step(bins_1, dup_last(ns_1 + ref_err), color=\"blue\", alpha=0.5,\n",
    "                        linewidth=0.5, where='post')\n",
    "\n",
    "        ax.fill_between(bins_1, dup_last(ns_1 - ref_err), dup_last(ns_1 + ref_err), \n",
    "                        facecolor=\"blue\", alpha=0.3, step='post')\n",
    "    \n",
    "    # Plot the generated data\n",
    "    alt_colors = [\"green\", \"red\", \"pink\"]\n",
    "    \n",
    "    for i, data in enumerate(data_list):\n",
    "        if not errorbars_fake[i]:\n",
    "            \n",
    "            # Modify the labels\n",
    "            if labels is None:\n",
    "                label = \"VAE\"\n",
    "            else:\n",
    "                label = labels[i]\n",
    "            \n",
    "            # Add the first trainer to the panel and use the default color code\n",
    "            if i == 0:\n",
    "                ns_0, bins_0, patches_0 = ax.hist(data, bins=bins, histtype='step', linewidth=2,\n",
    "                    alpha=1, density=density, label=label, color=color)\n",
    "            if i == 1:\n",
    "                ns_2, bins_2, patches_2 = ax.hist(data, bins=bins, histtype='step', linewidth=2,\n",
    "                    alpha=1, density=density, label=label, color=color)\n",
    "            else:\n",
    "                ax.hist(data, bins=bins, histtype='step', linewidth=2,\n",
    "                    alpha=1, density=density, label=label, color=alt_colors[i])\n",
    "    \n",
    "        else:\n",
    "            # labels\n",
    "            if labels is None:\n",
    "                label = \"VAE\"\n",
    "            else:\n",
    "                label = labels[i]\n",
    "                \n",
    "            data = data_list[i]\n",
    "            \n",
    "            dup_last = lambda a: np.append(a, a[-1])\n",
    "            \n",
    "            if i == 0:\n",
    "                bins_0 = bins\n",
    "                \n",
    "                counts, _ = np.histogram(data, bins_0, density=False)\n",
    "                ns_0, _ = np.histogram(data, bins_0, density=True)\n",
    "                \n",
    "                mask = (counts == 0)\n",
    "                counts[mask] = 1\n",
    "                \n",
    "                data_err = ns_0 / np.sqrt(counts)\n",
    "                    \n",
    "                data_err[mask] = 0\n",
    "                \n",
    "                ax.step(bins_0, dup_last(ns_0), color=alt_colors[i], alpha=1,\n",
    "                                linewidth=1, where='post', label=label)\n",
    "                \n",
    "                ax.step(bins_0, dup_last(ns_0 - data_err), color=alt_colors[i], alpha=0.5,\n",
    "                                linewidth=0.5, where='post')\n",
    "                ax.step(bins_0, dup_last(ns_0 + data_err), color=alt_colors[i], alpha=0.5,\n",
    "                                linewidth=0.5, where='post')\n",
    "\n",
    "                ax.fill_between(bins_0, dup_last(ns_0 - data_err), dup_last(ns_0 + data_err), \n",
    "                                facecolor=alt_colors[i], alpha=0.3, step='post')\n",
    "            elif i == 1:\n",
    "                bins_2 = bins\n",
    "                \n",
    "                counts, _ = np.histogram(data, bins_2, density=False)\n",
    "                ns_2, _ = np.histogram(data, bins_2, density=True)\n",
    "                \n",
    "                mask = (counts == 0)\n",
    "                counts[mask] = 1\n",
    "                \n",
    "                data_err = ns_2 / np.sqrt(counts)\n",
    "                    \n",
    "                data_err[mask] = 0\n",
    "                \n",
    "                ax.step(bins_2, dup_last(ns_2), color=alt_colors[i], alpha=1,\n",
    "                                linewidth=1, where='post', label=label)\n",
    "                \n",
    "                ax.step(bins_2, dup_last(ns_2 - data_err), color=alt_colors[i], alpha=0.5,\n",
    "                                linewidth=0.5, where='post')\n",
    "                ax.step(bins_2, dup_last(ns_2 + data_err), color=alt_colors[i], alpha=0.5,\n",
    "                                linewidth=0.5, where='post')\n",
    "\n",
    "                ax.fill_between(bins_0, dup_last(ns_2 - data_err), dup_last(ns_2 + data_err), \n",
    "                                facecolor=alt_colors[i], alpha=0.3, step='post')\n",
    "            \n",
    "            else:                \n",
    "                counts, _ = np.histogram(data, bins, density=False)\n",
    "                ns, _ = np.histogram(data, bins, density=True)\n",
    "                \n",
    "                mask = (counts == 0)\n",
    "                counts[mask] = 1\n",
    "                \n",
    "                data_err = ns / np.sqrt(counts)\n",
    "                    \n",
    "                data_err[mask] = 0\n",
    "                \n",
    "                ax.step(bins, dup_last(ns), color=alt_colors[i], alpha=1,\n",
    "                                linewidth=1, where='post', label=label)\n",
    "                \n",
    "                ax.step(bins, dup_last(ns - data_err), color=alt_colors[i], alpha=0.5,\n",
    "                                linewidth=0.5, where='post')\n",
    "                ax.step(bins, dup_last(ns + data_err), color=alt_colors[i], alpha=0.5,\n",
    "                                linewidth=0.5, where='post')\n",
    "\n",
    "                ax.fill_between(bins_0, dup_last(ns - data_err), dup_last(ns + data_err), \n",
    "                                facecolor=alt_colors[i], alpha=0.3, step='post')\n",
    "                \n",
    "        \n",
    "\n",
    "    if panel_ax is not None:\n",
    "        assert len(bins_0) == len(bins_1)\n",
    "        assert (bins_0 - bins_1 < 1.e-7).all()\n",
    "        \n",
    "        # prevent divisions by 0! Set these bars to 0\n",
    "        mask = ns_1 == 0\n",
    "        ns_1[mask] = 1\n",
    "        panel_data = ns_0/ns_1\n",
    "        \n",
    "        panel_data[mask] = 0\n",
    "        \n",
    "        widths = 1.2*(bins_1[1:] - bins_1[:-1])\n",
    "        panel_ax.axhline(1, color=\"red\", ls=\"--\")\n",
    "        panel_ax.hist(bins_0[:-1], bins[1:]-widths, weights=panel_data, histtype=\"step\", lw=2, label='Generated/GEANT')\n",
    "        \n",
    "\n",
    "        panel_data = ns_2/ns_1\n",
    "        \n",
    "        panel_data[mask] = 0\n",
    "        \n",
    "        widths = 1.2*(bins_1[1:] - bins_1[:-1])\n",
    "        panel_ax.axhline(1, color=\"red\", ls=\"--\")\n",
    "        panel_ax.hist(bins_0[:-1], bins[1:]-widths, weights=panel_data, histtype=\"step\", lw=2, label='Reconstructed/GEANT')\n",
    "        \n",
    "    ax.set_yscale(yscale)\n",
    "    ax.set_xscale(xscale)\n",
    "    if panel_ax is not None:\n",
    "        panel_ax.set_yscale(panel_scale)\n",
    "        panel_ax.set_xscale(xscale)\n",
    "\n",
    "    ax.set_xlim([vmin,vmax])\n",
    "    if panel_ax is not None:\n",
    "        panel_ax.set_xlim([vmin,vmax])\n",
    "        panel_ax.set_ylim([0.5, 1.5])\n",
    "        \n",
    "    if ymin is not None or ymax is not None:\n",
    "        ax.set_ylim((ymin, ymax))\n",
    "\n",
    "    if panel_ax is not None:\n",
    "        panel_ax.legend()\n",
    "\n",
    "    if axis_label:\n",
    "        if panel_ax is None:\n",
    "            ax.set_xlabel(axis_label, fontproperties=axislabelfont)\n",
    "        else:\n",
    "            panel_ax.set_xlabel(axis_label, fontproperties=axislabelfont)\n",
    "            \n",
    "    plt.xticks(fontproperties=tickfont)\n",
    "    plt.yticks(fontproperties=tickfont)\n",
    "    \n",
    "    ax.legend()\n",
    "\n",
    "    if create_fig:\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(file_name, bbox_inches='tight')\n",
    "        \n",
    "    # Why this line?\n",
    "    if panel_ax is None:\n",
    "        plt.close()\n",
    "\n",
    "def plot_all_hist(x_true, c_true, x_fakes, c_fakes, params, layer_boundaries, plot_dir, plot_name,\n",
    "                  single_plots=False, summary_plot=True, labels=None, errorbars_true=False, errorbars_fake=False):\n",
    "    \n",
    "    \n",
    "    threshold = params.get(\"threshold\", 1.e-4)\n",
    "    \n",
    "    # Load the hlf classes\n",
    "    hlf_true = data_util.get_hlf(x_true, c_true, params[\"particle_type\"], layer_boundaries, threshold=threshold, dataset=params.get(\"dataset\", 1))\n",
    "    \n",
    "    hlf_fakes = []\n",
    "    \n",
    "    for x_fake, c_fake in zip(x_fakes, c_fakes):\n",
    "        hlf_fakes.append(data_util.get_hlf(x_fake, c_fake, params[\"particle_type\"], layer_boundaries, threshold=threshold, dataset=params.get(\"dataset\", 1)))\n",
    "    \n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "    \n",
    "    plots = plotting.get_all_plot_parameters(hlf_true, params)\n",
    "    \n",
    "    for plot in plots:\n",
    "        plot[3][\"vmin\"] = None\n",
    "        plot[3][\"vmax\"] = None\n",
    "\n",
    "    \n",
    "    # Plot all the histogramms in one file\n",
    "    number_of_plots = len(plots)\n",
    "    rows = number_of_plots // 6\n",
    "    if number_of_plots%6 != 0:\n",
    "        rows += 1\n",
    "    heights = [1, 0.3, 0.3]*rows\n",
    "\n",
    "    fig, axs = plt.subplots(rows*3,6, dpi=500, figsize=(6*7,6*np.sum(heights)), gridspec_kw={'height_ratios': heights})\n",
    "\n",
    "    iteration = 0\n",
    "    for i in range(rows*3):\n",
    "        \n",
    "        if i%3 == 1:\n",
    "            iteration -= 6\n",
    "            \n",
    "        for j in range(6):\n",
    "            \n",
    "            if i % 3 == 2:\n",
    "                # Add one (small) invisible plot as whitespace\n",
    "                axs[i,j].set_visible(False)\n",
    "                continue\n",
    "            \n",
    "            elif iteration >= number_of_plots:\n",
    "                    # Plots are empty remove them\n",
    "                    axs[i,j].set_visible(False)\n",
    "                    iteration += 1\n",
    "                    continue\n",
    "            \n",
    "            \n",
    "            # Select the correct plot input for this axis\n",
    "            function, name, args1, args2 = plots[iteration]\n",
    "            \n",
    "            \n",
    "            if i % 3 == 0:\n",
    "                # plot the main data\n",
    "                plot_hist(\n",
    "                        file_name=None,\n",
    "                        data=[function(hlf_fake, **args1) for hlf_fake in hlf_fakes],\n",
    "                        reference=function(hlf_true, **args1),\n",
    "                        ax=axs[i,j],\n",
    "                        panel_ax=axs[i+1,j],\n",
    "                        labels=labels,\n",
    "                        errorbars_fake=errorbars_fake,\n",
    "                        errorbars_true=errorbars_true,\n",
    "                        **args2)\n",
    "                \n",
    "                # Hide the (shared) x-axis\n",
    "                axs[i,j].xaxis.set_visible(False)\n",
    "                \n",
    "                # Hide the first tick label\n",
    "                plt.setp(axs[i,j].get_yticklabels()[0], visible=False)  \n",
    "                iteration += 1\n",
    "\n",
    "            if i % 3 == 1:\n",
    "                plt.setp(axs[i,j].get_yticklabels()[-1], visible=False)\n",
    "                iteration += 1             \n",
    "\n",
    "    fig.subplots_adjust(hspace=0)\n",
    "    # fig.savefig(os.path.join(os.path.join(plot_dir,\"../\"), \"final.pdf\"), bbox_inches='tight', dpi=500)\n",
    "    fig.savefig(plot_dir+plot_name, bbox_inches='tight', dpi=500)\n",
    "    # Dont use tight_layout!\n",
    "    plt.close()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def load_trainer(directory, use_cuda=True, threshold=1.e-10):\n",
    "    use_cuda = torch.cuda.is_available() and use_cuda\n",
    "    device = 'cuda:0' if use_cuda else 'cpu' \n",
    "\n",
    "\n",
    "    with open(directory + \"/params.yaml\") as f:\n",
    "        params = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        \n",
    "    doc = Documenter(params['run_name'], existing_run=True, basedir=directory,\n",
    "                    log_name=\"log_jupyter.txt\", read_only=True)\n",
    "    \n",
    "    particle = params.get(\"particle_type\", \"piplus\")\n",
    "\n",
    "    dataset = params.get(\"dataset\", 1)\n",
    "    if \"data_path\" not in params:\n",
    "        particle_type = params.get(\"particle_type\", \"phoron\")\n",
    "        if dataset == 1:\n",
    "            # Load 2nd dataset to make sure we use no training showers\n",
    "            data_path = f\"/remote/gpu06/ernst/Master_Thesis/Datasets/Dataset1/dataset_1_{particle_type}s_2.hdf5\"\n",
    "        else:\n",
    "            data_path = f\"/remote/gpu06/ernst/Master_Thesis/Datasets/Dataset{dataset}/dataset_{dataset}_1.hdf5\"\n",
    "        params[\"data_path\"] = data_path\n",
    "    \n",
    "    params[\"threshold\"] = threshold\n",
    "    params[\"vae_dir\"] = os.path.join(directory, \"VAE\")\n",
    "    \n",
    "    trainer = ECAETrainer(params, device, doc, vae_dir=os.path.join(directory, \"VAE\"))\n",
    "    \n",
    "    return trainer, params, device, doc\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu05-gpu3\n"
     ]
    }
   ],
   "source": [
    "!cat $PBS_GPUFILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri May 26 13:35:45 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.85.05    Driver Version: 525.85.05    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "| 73%   87C    P2   228W / 250W |   6150MiB / 11264MiB |     85%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "| 62%   86C    P2   182W / 250W |   2280MiB / 11264MiB |     97%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:82:00.0 Off |                  N/A |\n",
      "| 28%   37C    P8    10W / 250W |      0MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  Off  | 00000000:83:00.0 Off |                  N/A |\n",
      "| 28%   50C    P8    11W / 250W |      0MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A   1503733      C   python3                          6148MiB |\n",
      "|    1   N/A  N/A   1515036      C   python3                          2278MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/remote/gpu06/ernst/Master_Thesis/vae_calo_challenge/CaloINN/results/2023_05_26_ECAE_seperated_by_einc_different_gamma/Use_einc_number_7_10_gamma',\n",
       " '/remote/gpu06/ernst/Master_Thesis/vae_calo_challenge/CaloINN/results/2023_05_26_ECAE_seperated_by_einc_different_gamma/Use_einc_number_7_4_gamma',\n",
       " '/remote/gpu06/ernst/Master_Thesis/vae_calo_challenge/CaloINN/results/2023_05_26_ECAE_seperated_by_einc_different_gamma/Use_einc_number_7_5_gamma',\n",
       " '/remote/gpu06/ernst/Master_Thesis/vae_calo_challenge/CaloINN/results/2023_05_26_ECAE_seperated_by_einc_different_gamma/Use_einc_number_7_7_gamma',\n",
       " '/remote/gpu06/ernst/Master_Thesis/vae_calo_challenge/CaloINN/results/2023_05_26_ECAE_seperated_by_einc_different_gamma/Use_einc_number_7_6_gamma',\n",
       " '/remote/gpu06/ernst/Master_Thesis/vae_calo_challenge/CaloINN/results/2023_05_26_ECAE_seperated_by_einc_different_gamma/Use_einc_number_7_9_gamma',\n",
       " '/remote/gpu06/ernst/Master_Thesis/vae_calo_challenge/CaloINN/results/2023_05_26_ECAE_seperated_by_einc_different_gamma/Use_einc_number_7_3_gamma',\n",
       " '/remote/gpu06/ernst/Master_Thesis/vae_calo_challenge/CaloINN/results/2023_05_26_ECAE_seperated_by_einc_different_gamma/Use_einc_number_7_8_gamma']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob(\"/remote/gpu06/ernst/Master_Thesis/vae_calo_challenge/CaloINN/results/2023_05_26_ECAE_seperated_by_einc_different_gamma/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the directory: /remote/gpu06/ernst/Master_Thesis/vae_calo_challenge/CaloINN/results/2023_05_26_ECAE_seperated_by_einc_different_gamma/Use_einc_number_7_10_gamma\n",
      "Using the directory: /remote/gpu06/ernst/Master_Thesis/vae_calo_challenge/CaloINN/results/2023_05_26_ECAE_seperated_by_einc_different_gamma/Use_einc_number_7_10_gamma/VAE\n",
      "cuda:0\n",
      "1\n",
      "Use incident energy 0.32768 (10000 events)\n",
      "(120991, 368) (120991, 11)\n",
      "(10000, 368) (10000, 11)\n",
      "CVAE(\n",
      "  (noise_layer_in): noise_layer()\n",
      "  (encoder): Sequential(\n",
      "    (fc0): Linear(in_features=374, out_features=700, bias=True)\n",
      "    (relu0): ReLU()\n",
      "    (dropout0): Dropout(p=0.0, inplace=False)\n",
      "    (fc1): Linear(in_features=700, out_features=400, bias=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout(p=0.0, inplace=False)\n",
      "    (fc2): Linear(in_features=400, out_features=150, bias=True)\n",
      "    (relu2): ReLU()\n",
      "    (dropout2): Dropout(p=0.0, inplace=False)\n",
      "    (fc_mu_logvar): Linear(in_features=150, out_features=100, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (fc0): Linear(in_features=56, out_features=150, bias=True)\n",
      "    (relu0): ReLU()\n",
      "    (dropout0): Dropout(p=0.0, inplace=False)\n",
      "    (fc1): Linear(in_features=150, out_features=400, bias=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout(p=0.0, inplace=False)\n",
      "    (fc2): Linear(in_features=400, out_features=700, bias=True)\n",
      "    (relu2): ReLU()\n",
      "    (dropout2): Dropout(p=0.0, inplace=False)\n",
      "    (fc_out): Linear(in_features=700, out_features=368, bias=True)\n",
      "  )\n",
      "  (noise_layer_out): noise_layer()\n",
      "  (norm_x_in): FixedLinearTransform()\n",
      "  (norm_x_out): FixedLinearTransform()\n",
      ")\n",
      "Input dimension: 105\n",
      "num samples out of bounds: 3\n",
      "number of parameters: 946440\n",
      "CINN(\n",
      "  (model): GraphINN(\n",
      "    (module_list): ModuleList(\n",
      "      (0): FixedLinearTransform()\n",
      "      (1): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (7): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (8): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (9): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (10): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (11): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (12): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (13): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (14): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (15): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (16): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (17): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (18): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "7 tensor(0.3277, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1545288/4061494415.py:25: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if type(data)==list and type(data[0]==np.ndarray):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the directory: /remote/gpu06/ernst/Master_Thesis/vae_calo_challenge/CaloINN/results/2023_05_26_ECAE_seperated_by_einc_different_gamma/Use_einc_number_7_4_gamma\n",
      "Using the directory: /remote/gpu06/ernst/Master_Thesis/vae_calo_challenge/CaloINN/results/2023_05_26_ECAE_seperated_by_einc_different_gamma/Use_einc_number_7_4_gamma/VAE\n",
      "cuda:0\n",
      "1\n",
      "Use incident energy 0.32768 (10000 events)\n",
      "(120991, 368) (120991, 11)\n",
      "(10000, 368) (10000, 11)\n",
      "CVAE(\n",
      "  (noise_layer_in): noise_layer()\n",
      "  (encoder): Sequential(\n",
      "    (fc0): Linear(in_features=374, out_features=700, bias=True)\n",
      "    (relu0): ReLU()\n",
      "    (dropout0): Dropout(p=0.0, inplace=False)\n",
      "    (fc1): Linear(in_features=700, out_features=400, bias=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout(p=0.0, inplace=False)\n",
      "    (fc2): Linear(in_features=400, out_features=150, bias=True)\n",
      "    (relu2): ReLU()\n",
      "    (dropout2): Dropout(p=0.0, inplace=False)\n",
      "    (fc_mu_logvar): Linear(in_features=150, out_features=100, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (fc0): Linear(in_features=56, out_features=150, bias=True)\n",
      "    (relu0): ReLU()\n",
      "    (dropout0): Dropout(p=0.0, inplace=False)\n",
      "    (fc1): Linear(in_features=150, out_features=400, bias=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout(p=0.0, inplace=False)\n",
      "    (fc2): Linear(in_features=400, out_features=700, bias=True)\n",
      "    (relu2): ReLU()\n",
      "    (dropout2): Dropout(p=0.0, inplace=False)\n",
      "    (fc_out): Linear(in_features=700, out_features=368, bias=True)\n",
      "  )\n",
      "  (noise_layer_out): noise_layer()\n",
      "  (norm_x_in): FixedLinearTransform()\n",
      "  (norm_x_out): FixedLinearTransform()\n",
      ")\n",
      "Input dimension: 105\n",
      "num samples out of bounds: 3\n",
      "number of parameters: 946440\n",
      "CINN(\n",
      "  (model): GraphINN(\n",
      "    (module_list): ModuleList(\n",
      "      (0): FixedLinearTransform()\n",
      "      (1): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (7): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (8): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (9): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (10): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (11): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (12): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (13): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (14): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (15): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (16): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (17): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (18): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "7 tensor(0.3277, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1545288/4061494415.py:25: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if type(data)==list and type(data[0]==np.ndarray):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the directory: /remote/gpu06/ernst/Master_Thesis/vae_calo_challenge/CaloINN/results/2023_05_26_ECAE_seperated_by_einc_different_gamma/Use_einc_number_7_5_gamma\n",
      "Using the directory: /remote/gpu06/ernst/Master_Thesis/vae_calo_challenge/CaloINN/results/2023_05_26_ECAE_seperated_by_einc_different_gamma/Use_einc_number_7_5_gamma/VAE\n",
      "cuda:0\n",
      "1\n",
      "Use incident energy 0.32768 (10000 events)\n",
      "(120991, 368) (120991, 11)\n",
      "(10000, 368) (10000, 11)\n",
      "CVAE(\n",
      "  (noise_layer_in): noise_layer()\n",
      "  (encoder): Sequential(\n",
      "    (fc0): Linear(in_features=374, out_features=700, bias=True)\n",
      "    (relu0): ReLU()\n",
      "    (dropout0): Dropout(p=0.0, inplace=False)\n",
      "    (fc1): Linear(in_features=700, out_features=400, bias=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout(p=0.0, inplace=False)\n",
      "    (fc2): Linear(in_features=400, out_features=150, bias=True)\n",
      "    (relu2): ReLU()\n",
      "    (dropout2): Dropout(p=0.0, inplace=False)\n",
      "    (fc_mu_logvar): Linear(in_features=150, out_features=100, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (fc0): Linear(in_features=56, out_features=150, bias=True)\n",
      "    (relu0): ReLU()\n",
      "    (dropout0): Dropout(p=0.0, inplace=False)\n",
      "    (fc1): Linear(in_features=150, out_features=400, bias=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout(p=0.0, inplace=False)\n",
      "    (fc2): Linear(in_features=400, out_features=700, bias=True)\n",
      "    (relu2): ReLU()\n",
      "    (dropout2): Dropout(p=0.0, inplace=False)\n",
      "    (fc_out): Linear(in_features=700, out_features=368, bias=True)\n",
      "  )\n",
      "  (noise_layer_out): noise_layer()\n",
      "  (norm_x_in): FixedLinearTransform()\n",
      "  (norm_x_out): FixedLinearTransform()\n",
      ")\n",
      "Input dimension: 105\n",
      "num samples out of bounds: 3\n",
      "number of parameters: 946440\n",
      "CINN(\n",
      "  (model): GraphINN(\n",
      "    (module_list): ModuleList(\n",
      "      (0): FixedLinearTransform()\n",
      "      (1): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (7): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (8): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (9): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (10): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (11): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (12): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (13): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (14): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (15): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (16): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (17): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (18): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "7 tensor(0.3277, device='cuda:0')\n",
      "Using the directory: /remote/gpu06/ernst/Master_Thesis/vae_calo_challenge/CaloINN/results/2023_05_26_ECAE_seperated_by_einc_different_gamma/Use_einc_number_7_7_gamma\n",
      "Using the directory: /remote/gpu06/ernst/Master_Thesis/vae_calo_challenge/CaloINN/results/2023_05_26_ECAE_seperated_by_einc_different_gamma/Use_einc_number_7_7_gamma/VAE\n",
      "cuda:0\n",
      "1\n",
      "Use incident energy 0.32768 (10000 events)\n",
      "(120991, 368) (120991, 11)\n",
      "(10000, 368) (10000, 11)\n",
      "CVAE(\n",
      "  (noise_layer_in): noise_layer()\n",
      "  (encoder): Sequential(\n",
      "    (fc0): Linear(in_features=374, out_features=700, bias=True)\n",
      "    (relu0): ReLU()\n",
      "    (dropout0): Dropout(p=0.0, inplace=False)\n",
      "    (fc1): Linear(in_features=700, out_features=400, bias=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout(p=0.0, inplace=False)\n",
      "    (fc2): Linear(in_features=400, out_features=150, bias=True)\n",
      "    (relu2): ReLU()\n",
      "    (dropout2): Dropout(p=0.0, inplace=False)\n",
      "    (fc_mu_logvar): Linear(in_features=150, out_features=100, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (fc0): Linear(in_features=56, out_features=150, bias=True)\n",
      "    (relu0): ReLU()\n",
      "    (dropout0): Dropout(p=0.0, inplace=False)\n",
      "    (fc1): Linear(in_features=150, out_features=400, bias=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout(p=0.0, inplace=False)\n",
      "    (fc2): Linear(in_features=400, out_features=700, bias=True)\n",
      "    (relu2): ReLU()\n",
      "    (dropout2): Dropout(p=0.0, inplace=False)\n",
      "    (fc_out): Linear(in_features=700, out_features=368, bias=True)\n",
      "  )\n",
      "  (noise_layer_out): noise_layer()\n",
      "  (norm_x_in): FixedLinearTransform()\n",
      "  (norm_x_out): FixedLinearTransform()\n",
      ")\n",
      "Input dimension: 105\n",
      "num samples out of bounds: 3\n",
      "number of parameters: 946440\n",
      "CINN(\n",
      "  (model): GraphINN(\n",
      "    (module_list): ModuleList(\n",
      "      (0): FixedLinearTransform()\n",
      "      (1): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (7): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (8): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (9): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (10): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (11): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (12): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (13): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (14): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (15): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (16): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (17): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (18): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "7 tensor(0.3277, device='cuda:0')\n",
      "Using the directory: /remote/gpu06/ernst/Master_Thesis/vae_calo_challenge/CaloINN/results/2023_05_26_ECAE_seperated_by_einc_different_gamma/Use_einc_number_7_6_gamma\n",
      "Using the directory: /remote/gpu06/ernst/Master_Thesis/vae_calo_challenge/CaloINN/results/2023_05_26_ECAE_seperated_by_einc_different_gamma/Use_einc_number_7_6_gamma/VAE\n",
      "cuda:0\n",
      "1\n",
      "Use incident energy 0.32768 (10000 events)\n",
      "(120991, 368) (120991, 11)\n",
      "(10000, 368) (10000, 11)\n",
      "CVAE(\n",
      "  (noise_layer_in): noise_layer()\n",
      "  (encoder): Sequential(\n",
      "    (fc0): Linear(in_features=374, out_features=700, bias=True)\n",
      "    (relu0): ReLU()\n",
      "    (dropout0): Dropout(p=0.0, inplace=False)\n",
      "    (fc1): Linear(in_features=700, out_features=400, bias=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout(p=0.0, inplace=False)\n",
      "    (fc2): Linear(in_features=400, out_features=150, bias=True)\n",
      "    (relu2): ReLU()\n",
      "    (dropout2): Dropout(p=0.0, inplace=False)\n",
      "    (fc_mu_logvar): Linear(in_features=150, out_features=100, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (fc0): Linear(in_features=56, out_features=150, bias=True)\n",
      "    (relu0): ReLU()\n",
      "    (dropout0): Dropout(p=0.0, inplace=False)\n",
      "    (fc1): Linear(in_features=150, out_features=400, bias=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout(p=0.0, inplace=False)\n",
      "    (fc2): Linear(in_features=400, out_features=700, bias=True)\n",
      "    (relu2): ReLU()\n",
      "    (dropout2): Dropout(p=0.0, inplace=False)\n",
      "    (fc_out): Linear(in_features=700, out_features=368, bias=True)\n",
      "  )\n",
      "  (noise_layer_out): noise_layer()\n",
      "  (norm_x_in): FixedLinearTransform()\n",
      "  (norm_x_out): FixedLinearTransform()\n",
      ")\n",
      "Input dimension: 105\n",
      "num samples out of bounds: 3\n",
      "number of parameters: 946440\n",
      "CINN(\n",
      "  (model): GraphINN(\n",
      "    (module_list): ModuleList(\n",
      "      (0): FixedLinearTransform()\n",
      "      (1): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (7): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (8): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (9): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (10): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (11): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (12): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (13): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (14): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (15): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (16): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (17): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (18): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "7 tensor(0.3277, device='cuda:0')\n",
      "Using the directory: /remote/gpu06/ernst/Master_Thesis/vae_calo_challenge/CaloINN/results/2023_05_26_ECAE_seperated_by_einc_different_gamma/Use_einc_number_7_9_gamma\n",
      "Using the directory: /remote/gpu06/ernst/Master_Thesis/vae_calo_challenge/CaloINN/results/2023_05_26_ECAE_seperated_by_einc_different_gamma/Use_einc_number_7_9_gamma/VAE\n",
      "cuda:0\n",
      "1\n",
      "Use incident energy 0.32768 (10000 events)\n",
      "(120991, 368) (120991, 11)\n",
      "(10000, 368) (10000, 11)\n",
      "CVAE(\n",
      "  (noise_layer_in): noise_layer()\n",
      "  (encoder): Sequential(\n",
      "    (fc0): Linear(in_features=374, out_features=700, bias=True)\n",
      "    (relu0): ReLU()\n",
      "    (dropout0): Dropout(p=0.0, inplace=False)\n",
      "    (fc1): Linear(in_features=700, out_features=400, bias=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout(p=0.0, inplace=False)\n",
      "    (fc2): Linear(in_features=400, out_features=150, bias=True)\n",
      "    (relu2): ReLU()\n",
      "    (dropout2): Dropout(p=0.0, inplace=False)\n",
      "    (fc_mu_logvar): Linear(in_features=150, out_features=100, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (fc0): Linear(in_features=56, out_features=150, bias=True)\n",
      "    (relu0): ReLU()\n",
      "    (dropout0): Dropout(p=0.0, inplace=False)\n",
      "    (fc1): Linear(in_features=150, out_features=400, bias=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout(p=0.0, inplace=False)\n",
      "    (fc2): Linear(in_features=400, out_features=700, bias=True)\n",
      "    (relu2): ReLU()\n",
      "    (dropout2): Dropout(p=0.0, inplace=False)\n",
      "    (fc_out): Linear(in_features=700, out_features=368, bias=True)\n",
      "  )\n",
      "  (noise_layer_out): noise_layer()\n",
      "  (norm_x_in): FixedLinearTransform()\n",
      "  (norm_x_out): FixedLinearTransform()\n",
      ")\n",
      "Input dimension: 105\n",
      "num samples out of bounds: 3\n",
      "number of parameters: 946440\n",
      "CINN(\n",
      "  (model): GraphINN(\n",
      "    (module_list): ModuleList(\n",
      "      (0): FixedLinearTransform()\n",
      "      (1): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (7): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (8): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (9): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (10): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (11): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (12): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (13): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (14): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (15): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (16): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (17): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (18): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "7 tensor(0.3277, device='cuda:0')\n",
      "Using the directory: /remote/gpu06/ernst/Master_Thesis/vae_calo_challenge/CaloINN/results/2023_05_26_ECAE_seperated_by_einc_different_gamma/Use_einc_number_7_3_gamma\n",
      "Using the directory: /remote/gpu06/ernst/Master_Thesis/vae_calo_challenge/CaloINN/results/2023_05_26_ECAE_seperated_by_einc_different_gamma/Use_einc_number_7_3_gamma/VAE\n",
      "cuda:0\n",
      "1\n",
      "Use incident energy 0.32768 (10000 events)\n",
      "(120991, 368) (120991, 11)\n",
      "(10000, 368) (10000, 11)\n",
      "CVAE(\n",
      "  (noise_layer_in): noise_layer()\n",
      "  (encoder): Sequential(\n",
      "    (fc0): Linear(in_features=374, out_features=700, bias=True)\n",
      "    (relu0): ReLU()\n",
      "    (dropout0): Dropout(p=0.0, inplace=False)\n",
      "    (fc1): Linear(in_features=700, out_features=400, bias=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout(p=0.0, inplace=False)\n",
      "    (fc2): Linear(in_features=400, out_features=150, bias=True)\n",
      "    (relu2): ReLU()\n",
      "    (dropout2): Dropout(p=0.0, inplace=False)\n",
      "    (fc_mu_logvar): Linear(in_features=150, out_features=100, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (fc0): Linear(in_features=56, out_features=150, bias=True)\n",
      "    (relu0): ReLU()\n",
      "    (dropout0): Dropout(p=0.0, inplace=False)\n",
      "    (fc1): Linear(in_features=150, out_features=400, bias=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout(p=0.0, inplace=False)\n",
      "    (fc2): Linear(in_features=400, out_features=700, bias=True)\n",
      "    (relu2): ReLU()\n",
      "    (dropout2): Dropout(p=0.0, inplace=False)\n",
      "    (fc_out): Linear(in_features=700, out_features=368, bias=True)\n",
      "  )\n",
      "  (noise_layer_out): noise_layer()\n",
      "  (norm_x_in): FixedLinearTransform()\n",
      "  (norm_x_out): FixedLinearTransform()\n",
      ")\n",
      "Input dimension: 105\n",
      "num samples out of bounds: 3\n",
      "number of parameters: 946440\n",
      "CINN(\n",
      "  (model): GraphINN(\n",
      "    (module_list): ModuleList(\n",
      "      (0): FixedLinearTransform()\n",
      "      (1): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (7): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (8): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (9): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (10): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (11): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (12): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (13): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (14): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (15): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (16): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (17): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (18): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "7 tensor(0.3277, device='cuda:0')\n",
      "Using the directory: /remote/gpu06/ernst/Master_Thesis/vae_calo_challenge/CaloINN/results/2023_05_26_ECAE_seperated_by_einc_different_gamma/Use_einc_number_7_8_gamma\n",
      "Using the directory: /remote/gpu06/ernst/Master_Thesis/vae_calo_challenge/CaloINN/results/2023_05_26_ECAE_seperated_by_einc_different_gamma/Use_einc_number_7_8_gamma/VAE\n",
      "cuda:0\n",
      "1\n",
      "Use incident energy 0.32768 (10000 events)\n",
      "(120991, 368) (120991, 11)\n",
      "(10000, 368) (10000, 11)\n",
      "CVAE(\n",
      "  (noise_layer_in): noise_layer()\n",
      "  (encoder): Sequential(\n",
      "    (fc0): Linear(in_features=374, out_features=700, bias=True)\n",
      "    (relu0): ReLU()\n",
      "    (dropout0): Dropout(p=0.0, inplace=False)\n",
      "    (fc1): Linear(in_features=700, out_features=400, bias=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout(p=0.0, inplace=False)\n",
      "    (fc2): Linear(in_features=400, out_features=150, bias=True)\n",
      "    (relu2): ReLU()\n",
      "    (dropout2): Dropout(p=0.0, inplace=False)\n",
      "    (fc_mu_logvar): Linear(in_features=150, out_features=100, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (fc0): Linear(in_features=56, out_features=150, bias=True)\n",
      "    (relu0): ReLU()\n",
      "    (dropout0): Dropout(p=0.0, inplace=False)\n",
      "    (fc1): Linear(in_features=150, out_features=400, bias=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout(p=0.0, inplace=False)\n",
      "    (fc2): Linear(in_features=400, out_features=700, bias=True)\n",
      "    (relu2): ReLU()\n",
      "    (dropout2): Dropout(p=0.0, inplace=False)\n",
      "    (fc_out): Linear(in_features=700, out_features=368, bias=True)\n",
      "  )\n",
      "  (noise_layer_out): noise_layer()\n",
      "  (norm_x_in): FixedLinearTransform()\n",
      "  (norm_x_out): FixedLinearTransform()\n",
      ")\n",
      "Input dimension: 105\n",
      "num samples out of bounds: 3\n",
      "number of parameters: 946440\n",
      "CINN(\n",
      "  (model): GraphINN(\n",
      "    (module_list): ModuleList(\n",
      "      (0): FixedLinearTransform()\n",
      "      (1): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (7): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (8): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (9): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (10): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (11): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (12): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (13): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (14): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (15): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (16): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (17): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (18): RationalQuadraticSplineBlock(\n",
      "        (softplus): Softplus(beta=0.5, threshold=20)\n",
      "        (subnet): Subnet(\n",
      "          (layers): Sequential(\n",
      "            (0): Linear(in_features=54, out_features=32, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=32, out_features=1508, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "7 tensor(0.3277, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "directories = glob(\"/remote/gpu06/ernst/Master_Thesis/vae_calo_challenge/CaloINN/results/2023_05_26_ECAE_seperated_by_einc_different_gamma/*\")\n",
    "\n",
    "for directory in directories:\n",
    "    trainer, params, device, doc = load_trainer(directory)\n",
    "    trainer.load()\n",
    "    \n",
    "    x = torch.cat((trainer.vae_trainer.train_loader.data, trainer.vae_trainer.test_loader.data), axis=0)\n",
    "    c = torch.cat((trainer.vae_trainer.train_loader.cond, trainer.vae_trainer.test_loader.cond), axis=0)\n",
    "    \n",
    "    x_gen, c_gen = trainer.generate(len(x))\n",
    "    x_reco = trainer.vae_trainer.get_reco(x, c)\n",
    "\n",
    "    base_path = \"/remote/gpu06/ernst/Master_Thesis/vae_calo_challenge/CaloINN/notebooks/plots/09___1.6e-01_hyperparam_tests\"\n",
    "    \n",
    "    e_incs = torch.unique(c[..., 0])\n",
    "    i = params[\"e_inc_index\"]\n",
    "    print(i, e_incs[0])\n",
    "    plot_dir = base_path + \"/\"\n",
    "    \n",
    "    gamma = np.log10(params[\"VAE_gamma\"])\n",
    "    plot_name = f\"gamma_{gamma:0.1e}.pdf\"\n",
    "    \n",
    "    plot_all_hist(x, c, [x_gen, x_reco], [c_gen, c], params, layer_boundaries=trainer.layer_boundaries,\n",
    "                  labels=[\"Generated\", \"Reconstructed\"], errorbars_true=True, errorbars_fake=[True, False],\n",
    "                  plot_dir=plot_dir, plot_name=plot_name, single_plots=False, summary_plot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ernst-CaloINN] *",
   "language": "python",
   "name": "conda-env-ernst-CaloINN-py"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
