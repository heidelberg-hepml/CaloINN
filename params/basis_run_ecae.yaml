# General

# Documenter information
run_name: add_inn
# block_name: test_runs
vae_dir: "/remote/gpu06/ernst/Master_Thesis/add_VAE/CaloINN/results/2023_02_15_105358_mae_on_both_-5_noise_much_larger"
# Data
dtype: float32
particle_type: piplus


# VAE

# VAE Preprocessing
alpha: 1.e-6
VAE_width_noise: 1.e-5
# VAE Training
VAE_lr: 5.e-4
VAE_batch_size: 256
VAE_n_epochs: 500
VAE_save_interval: 100
VAE_keep_models: 1001
# VAE Architecture
VAE_hidden_sizes: [4500, 1000, 150]
VAE_latent_dim: 50
VAE_beta: 1.e-5
VAE_gamma: 1.e+4


# INN

# Data
latent_type: pre_sampling # post_sampling or pre_sampling
# INN Preprocessing
logit_transformation: False
log_cond: True
# INN Training
lr: 5.e-5
max_lr: 5.e-4
batch_size: 256
lr_scheduler: one_cycle_lr
weight_decay: 0.
betas: [0.9, 0.999]
n_epochs: 200
save_interval: 50
keep_models: 1000
# Bayesian Setup
bayesian: False
# INN Architecture
n_blocks: 18
internal_size: 32
layers_per_block: 3
coupling_type: rational_quadratic
bounds_init: 20
permute_soft: False
num_bins: 10
dropout: 0.0


# Classifier Test
do_classifier_test: True
# Classifier Training
classifier_sigmoid_in_BCE: True
classifier_lr: 2.e-4
classifier_n_epochs: 100
classifier_batch_size: 1000
classifier_runs: 5
# Classifier Architecture
modes: ["DNN"]
DNN_hidden_layers: 2
DNN_hidden_neurons: 512
DNN_dropout: 0.
# Classifier Preprocessing
classifier_threshold: True #needed
classifier_normalize: False #needed
classifier_use_logit: False #needed

